---
title: Mechine Learning By Andrew Ng
date: 2018-8-21 15:28:21
tags: [人工智能,算法详解]
---

## Basic concepts

- Supervised Learning, Disciminative Algorithms [[pdf](class-notes/cs229-notes1.pdf)]
- Problem Set 0 [[pdf](class-notes/ps0.pdf)]

## Supersived learning

- Supervised learning setup. LMS. [[pdf](class-notes/cs229-notes1.pdf)] 
- Discussion Section: Linear Algebra [[Notes](class-notes/cs229-linalg.pdf)]
- Logistic regression. Perceptron. Exponential family [[pdf](class-notes/cs229-notes1.pdf)] 
- Problem Set 1 [[pdf](class-notes/ps1.pdf)]
- Discussion Section: Probability [[pdf](class-notes/cs229-prob.pdf)]\[[Slides](class-notes/cs229-prob-slide.pdf)]
- Generative learning algorithms. Gaussian discriminant analysis. Navie Bayes [[pdf](class-notes/cs229-notes2.pdf)]
- Support vector machines [[pdf](class-notes/cs229-notes3.pdf)]
- Discussion Section: Vectorization [[Slides](class-notes/Vectorization_Section.pdf)]\[[KNN](class-notes/knn.py)]\[[Logistic Regression](class-notes/lr.ipynb)]\[[Softmax Regression](class-notes/sr.ipynb)]\[[Images](class-notes/images.csv)]\[[Labels](class-notes/labels.csv)]

## Practice ML advice

- Bias/variance tradeoff and error analysis [[pdf](class-notes/error-analysis.pdf)]
- Learning Theory [[pdf](class-notes/cs229-notes4.pdf)]
- Regularization and Model Selection [[pdf](class-notes/cs229-notes5.pdf)]
- Online Learning and the Perceptron Algorithm. (opitonal reading) [[pdf](class-notes/cs229-notes6.pdf)]
- Advice on applying machine learning [[pdf](class-notes/ML-advice.pdf)]
- Problem Set 2 [[pdf](class-notes/ps2.pdf)]
- Discussion Section: Convex Optimization Part I [[pdf](class-notes/cs229-cvxopt.pdf)] Part II [[pdf](class-notes/cs229-cvxopt2.pdf)]

## Deep Learning

- NN architecture. Vectorization. Forward/Back propagation [[pdf](class-notes/cs229-notes-deep_learning.pdf)]
- Additional notes on backpropagation [[pdf](class-notes/cs229-notes-backprop.pdf)]
- Discussion Section: Evaluation Metrics [[Slides](class-notes/evaluation_metrics.pdf)]

## Unsupervised Learning

- Unsupervied Learning, K-means clustering. [[pdf](class-notes/cs229-notes7a.pdf)]
- Mixture of Gaussians [[pdf](class-notes/cs229-notes7b.pdf)]
- The EM Algorithm [[pdf](class-notes/cs229-notes8.pdf)]
- Factor Analysis [[pdf](class-notes/cs229-notes9.pdf)]
- Principal Components Analysis [[pdf](class-notes/cs229-notes10.pdf)]
- Independent Components Analysis [[pdf](class-notes/cs229-notes11.pdf)]
- Problem Set 3 [[pdf](class-notes/ps3.pdf)]

## Reinforcement learning and control

- Reinforcement Learning and Control [[pdf](class-notes/cs229-notes12.pdf)]
- LQR, DDP and LQG [[pdf](class-notes/cs229-notes13.pdf)]
- Problem Set 4 [[pdf](class-notes/ps4.pdf)]
- Generative Adversarial Networks (GANs) [[pdf](class-notes/1406.2661.pdf)]
- Adversarial examples in ML [[pdf](class-notes/1412.6572.pdf)]

## Supplementary Notes

1. Binary classification with +/-1 labels [[pdf](class-notes/loss-functions.pdf)]
2. Boosting algorithms and weak learning [[pdf](class-notes/boosting.pdf)]
3. Functional after implementing stump_booster.m in PS2. [[here](class-notes/boosting_example.m)]
4. The representer theorem [[pdf](class-notes/representer-function.pdf)]
5. Hoeffding's inequality [[pdf](class-notes/hoeffding.pdf)]

